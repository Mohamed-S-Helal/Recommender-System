{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Collaborative Filtering Recommendation\n\nOne of the most popular methods for making recommendations is **collaborative filtering**.  In collaborative filtering, you are using the collaboration of user-item recommendations to assist in making new recommendations.  \n\nThere are two main methods of performing collaborative filtering:\n\n1. **Neighborhood-Based Collaborative Filtering**, which is based on the idea that we can either correlate items that are similar to provide recommendations or we can correlate users to one another to provide recommendations.\n\n2. **Model Based Collaborative Filtering**, which is based on the idea that we can use machine learning and other mathematical models to understand the relationships that exist amongst items and users to predict ratings and provide ratings.\n\n\nIn this notebook, you will be working on performing **neighborhood-based collaborative filtering**.  There are two main methods for performing collaborative filtering:\n\n1. **User-based collaborative filtering:** In this type of recommendation, users related to the user you would like to make recommendations for are used to create a recommendation.\n\n2. **Item-based collaborative filtering:** In this type of recommendation, first you need to find the items that are most related to each other item (based on similar ratings).  Then you can use the ratings of an individual on those similar items to understand if a user will like the new item.\n\nIn this notebook you will be implementing **user-based collaborative filtering**.  However, it is easy to extend this approach to make recommendations using **item-based collaborative filtering**.  First, let's read in our data and necessary libraries.","metadata":{"id":"USveXvvWSMPb"}},{"cell_type":"markdown","source":"## User-based Collaborative Filtering Recommendation System\n","metadata":{}},{"cell_type":"code","source":"# !pip install gdown -q\n# import gdown","metadata":{"execution":{"iopub.status.busy":"2022-03-21T23:48:04.359919Z","iopub.execute_input":"2022-03-21T23:48:04.360171Z","iopub.status.idle":"2022-03-21T23:48:11.798225Z","shell.execute_reply.started":"2022-03-21T23:48:04.360147Z","shell.execute_reply":"2022-03-21T23:48:11.796887Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade --no-cache-dir gdown -q\n!gdown 1vo5amPt4t2IeHq3wQhq_fXAOQtoKGFKM\n!gdown 1CUOpMwUmYh_L6Ni-e-hVrlpCLJUb3FtE\n!gdown 19QHcex_bHy8Yl7sYtx0a3knX99aEGCci","metadata":{"id":"emFCfHNcSlMy","outputId":"a2267a8b-6c0e-46d7-d4a5-3a23b3ab5fb6","execution":{"iopub.status.busy":"2022-03-22T09:12:51.715337Z","iopub.execute_input":"2022-03-22T09:12:51.716084Z","iopub.status.idle":"2022-03-22T09:13:17.818864Z","shell.execute_reply.started":"2022-03-22T09:12:51.716046Z","shell.execute_reply":"2022-03-22T09:13:17.817778Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import pickle\n\n# write python dict to a file\nmydict = {'a': 1, 'b': 2, 'c': 3}\noutput = open('myfile.pkl', 'wb')\npickle.dump(mydict, output)\noutput.close()\n\n# read python dict back from the file\npkl_file = open('myfile.pkl', 'rb')\nmydict2 = pickle.load(pkl_file)\npkl_file.close()\n\nprint (mydict)\nprint (mydict2)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T20:28:26.416635Z","iopub.execute_input":"2021-12-27T20:28:26.417084Z","iopub.status.idle":"2021-12-27T20:28:26.446658Z","shell.execute_reply.started":"2021-12-27T20:28:26.416959Z","shell.execute_reply":"2021-12-27T20:28:26.445699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls ..","metadata":{"execution":{"iopub.status.busy":"2021-12-27T20:30:28.889664Z","iopub.execute_input":"2021-12-27T20:30:28.890068Z","iopub.status.idle":"2021-12-27T20:30:29.652884Z","shell.execute_reply.started":"2021-12-27T20:30:28.890029Z","shell.execute_reply":"2021-12-27T20:30:29.652029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp myfile.pkl ","metadata":{"execution":{"iopub.status.busy":"2021-12-27T20:28:34.276757Z","iopub.execute_input":"2021-12-27T20:28:34.277927Z","iopub.status.idle":"2021-12-27T20:28:35.047435Z","shell.execute_reply.started":"2021-12-27T20:28:34.277868Z","shell.execute_reply":"2021-12-27T20:28:35.046283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -r ../working ../new","metadata":{"execution":{"iopub.status.busy":"2021-12-26T22:37:45.303766Z","iopub.execute_input":"2021-12-26T22:37:45.304066Z","iopub.status.idle":"2021-12-26T22:37:46.106557Z","shell.execute_reply.started":"2021-12-26T22:37:45.304032Z","shell.execute_reply":"2021-12-26T22:37:46.105379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cd ../ && ls .","metadata":{"execution":{"iopub.status.busy":"2021-12-26T22:35:05.54395Z","iopub.execute_input":"2021-12-26T22:35:05.544852Z","iopub.status.idle":"2021-12-26T22:35:06.383356Z","shell.execute_reply.started":"2021-12-26T22:35:05.544742Z","shell.execute_reply":"2021-12-26T22:35:06.382461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.make_archive('output_filename', 'zip', '../new')","metadata":{"execution":{"iopub.status.busy":"2021-12-26T22:39:56.434148Z","iopub.execute_input":"2021-12-26T22:39:56.434508Z","iopub.status.idle":"2021-12-26T22:39:56.444045Z","shell.execute_reply.started":"2021-12-26T22:39:56.434454Z","shell.execute_reply":"2021-12-26T22:39:56.443537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tests as t\nfrom scipy.sparse import csr_matrix\nfrom IPython.display import HTML\n\n\n%matplotlib inline\n\n# Read in the datasets\nmovies = pd.read_csv('movies_clean.csv')\nreviews = pd.read_csv('reviews_clean.csv')\n\ndel movies['Unnamed: 0']\ndel reviews['Unnamed: 0']\n\n","metadata":{"id":"AA3zvHc7SMPu","outputId":"e52e88e1-7c1d-4470-c7db-2da8e722e1de","execution":{"iopub.status.busy":"2022-03-22T09:13:44.172844Z","iopub.execute_input":"2022-03-22T09:13:44.173107Z","iopub.status.idle":"2022-03-22T09:13:45.563887Z","shell.execute_reply.started":"2022-03-22T09:13:44.173080Z","shell.execute_reply":"2022-03-22T09:13:45.563052Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"movies.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T09:14:04.323441Z","iopub.execute_input":"2022-03-22T09:14:04.323708Z","iopub.status.idle":"2022-03-22T09:14:04.340780Z","shell.execute_reply.started":"2022-03-22T09:14:04.323679Z","shell.execute_reply":"2022-03-22T09:14:04.340053Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"reviews.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T09:14:08.538686Z","iopub.execute_input":"2022-03-22T09:14:08.538994Z","iopub.status.idle":"2022-03-22T09:14:08.555285Z","shell.execute_reply.started":"2022-03-22T09:14:08.538962Z","shell.execute_reply":"2022-03-22T09:14:08.554728Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### User-Item Matrix\n\nIn order to calculate the similarities, it is common to put values in a matrix.  In this matrix, users are identified by each row, and items are represented by columns.  ","metadata":{"id":"tDl7Y69TSMP0"}},{"cell_type":"code","source":"user_items = reviews[['user_id', 'movie_id', 'rating']]\nuser_items.head()","metadata":{"id":"P9Z1e4LMSMP5","outputId":"da11c344-d3f8-475c-962d-5179a05ceec5","execution":{"iopub.status.busy":"2022-03-22T09:15:34.760625Z","iopub.execute_input":"2022-03-22T09:15:34.761131Z","iopub.status.idle":"2022-03-22T09:15:34.876633Z","shell.execute_reply.started":"2022-03-22T09:15:34.761090Z","shell.execute_reply":"2022-03-22T09:15:34.875933Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Creating the User-Item Matrix\n\nIn order to create the user-items matrix (like the one above), I personally started by using a [pivot table](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.pivot_table.html). \n\nHowever, I quickly ran into a memory error (a common theme throughout this notebook).  I will help you navigate around many of the errors I had, and achieve useful collaborative filtering results! \n\n_____\n\n`1.` Create a matrix where the users are the rows, the movies are the columns, and the ratings exist in each cell, or a NaN exists in cells where a user hasn't rated a particular movie. If you get a memory error (like I did), [this link here](https://stackoverflow.com/questions/39648991/pandas-dataframe-pivot-memory-error) might help you!","metadata":{"id":"5lw3Zs2eSMP7"}},{"cell_type":"code","source":"# Create user-by-item matrix\nuser_by_movie = user_items.groupby(['user_id', 'movie_id'])['rating'].max().unstack()","metadata":{"id":"0LNPWZeLSMP8","execution":{"iopub.status.busy":"2022-03-22T09:16:55.957552Z","iopub.execute_input":"2022-03-22T09:16:55.958271Z","iopub.status.idle":"2022-03-22T09:17:06.931107Z","shell.execute_reply.started":"2022-03-22T09:16:55.958224Z","shell.execute_reply":"2022-03-22T09:17:06.930406Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# user_items.head().groupby(['user_id', 'movie_id'])['rating'].max().unstack()","metadata":{"execution":{"iopub.status.busy":"2021-11-25T22:34:41.855655Z","iopub.execute_input":"2021-11-25T22:34:41.85608Z","iopub.status.idle":"2021-11-25T22:34:41.860796Z","shell.execute_reply.started":"2021-11-25T22:34:41.85604Z","shell.execute_reply":"2021-11-25T22:34:41.85969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"user_by_movie","metadata":{"scrolled":true,"id":"hGUoYoH7SMP9","execution":{"iopub.status.busy":"2022-03-22T09:17:14.497741Z","iopub.execute_input":"2022-03-22T09:17:14.498032Z","iopub.status.idle":"2022-03-22T09:17:14.559379Z","shell.execute_reply.started":"2022-03-22T09:17:14.498003Z","shell.execute_reply":"2022-03-22T09:17:14.558576Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Check your results below to make sure your matrix is ready for the upcoming sections.","metadata":{"id":"Lt1ahVsrSMP9"}},{"cell_type":"markdown","source":"`2.` Now that we have a matrix of users by movies, we this matrix to create a dictionary where the key is each user and the value is an array of the movies each user has rated.","metadata":{"id":"9KQhSRbuSMP_"}},{"cell_type":"code","source":"# Create a dictionary with users and corresponding movies seen\n\ndef movies_watched(user_id):\n    '''\n    INPUT:\n    user_id - the user_id of an individual as int\n    OUTPUT:\n    movies - an array of movies the user has watched\n    '''\n\n    return reviews.movie_id[reviews.user_id == user_id].tolist()\n\n\ndef create_user_movie_dict():\n    '''\n    INPUT: None\n    OUTPUT: movies_seen - a dictionary where each key is a user_id and the value is an array of movie_ids\n    \n    Creates the movies_seen dictionary\n    '''\n    \n    return {userId:movies_watched(userId) for userId in reviews.user_id.unique()}\n\n\n# Use your function to return dictionary\nmovies_seen = create_user_movie_dict()","metadata":{"id":"sfC-rUReSMQA","execution":{"iopub.status.busy":"2022-03-22T09:18:05.771880Z","iopub.execute_input":"2022-03-22T09:18:05.772161Z","iopub.status.idle":"2022-03-22T09:18:45.439536Z","shell.execute_reply.started":"2022-03-22T09:18:05.772121Z","shell.execute_reply":"2022-03-22T09:18:45.438837Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"`3.` If a user hasn't rated more than 2 movies, we consider these users \"too new\".  Create a new dictionary that only contains users who have rated more than 2 movies.  This dictionary will be used for all the final steps of this workbook.","metadata":{"id":"w6a3zkvfSMQB"}},{"cell_type":"code","source":"# Remove individuals who have watched 2 or fewer movies - don't have enough data to make recs\n\ndef create_movies_to_analyze(movies_seen, lower_bound=2):\n    '''\n    INPUT:  \n    movies_seen - a dictionary where each key is a user_id and the value is an array of movie_ids\n    lower_bound - (an int) a user must have more movies seen than the lower bound to be added to the movies_to_analyze dictionary\n\n    OUTPUT: \n    movies_to_analyze - a dictionary where each key is a user_id and the value is an array of movie_ids\n    \n    The movies_seen and movies_to_analyze dictionaries should be the same except that the output dictionary has removed \n    \n    '''\n    \n    # Do things to create updated dictionary\n    \n    return {userId:movieList for userId,movieList in movies_seen.items() if len(movieList)>lower_bound}\n\n\n# Use your function to return your updated dictionary\nmovies_to_analyze = create_movies_to_analyze(movies_seen)","metadata":{"id":"LtQjkv3KSMQC","execution":{"iopub.status.busy":"2022-03-22T09:18:45.457729Z","iopub.execute_input":"2022-03-22T09:18:45.458283Z","iopub.status.idle":"2022-03-22T09:18:45.479398Z","shell.execute_reply.started":"2022-03-22T09:18:45.458251Z","shell.execute_reply":"2022-03-22T09:18:45.478407Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### Calculating User Similarities\n\nNow that we have set up the **movies_to_analyze** dictionary, it is time to take a closer look at the similarities between users.  Below is the pseudocode for how I thought about determining the similarity between users:\n\n```\nfor user1 in movies_to_analyze\n    for user2 in movies_to_analyze\n        see how many movies match between the two users\n        if more than two movies in common\n            pull the overlapping movies\n            compute the distance/similarity metric between ratings on the same movies for the two users\n            store the users and the distance metric\n ","metadata":{"id":"FtwLr1SzSMQE"}},{"cell_type":"code","source":"def compute_correlation(user1, user2):\n    '''\n    INPUT\n    user1 - int user_id\n    user2 - int user_id\n    OUTPUT\n    the correlation between the matching ratings between the two users\n    '''\n    m1 = movies_to_analyze[user1]\n    m2 = movies_to_analyze[user2]\n    m12 = np.intersect1d(m1,m2)\n    r1 = [reviews.rating[(reviews['user_id'] == user1) & (reviews['movie_id'] == mi)].tolist()[0] for mi in m12]\n    r2 = [reviews.rating[(reviews['user_id'] == user2) & (reviews['movie_id'] == mi)].tolist()[0] for mi in m12]\n    return np.corrcoef(r1,r2)[0,1] #return the correlation","metadata":{"id":"hUKqEEmISMQE","execution":{"iopub.status.busy":"2022-03-22T09:19:51.416769Z","iopub.execute_input":"2022-03-22T09:19:51.417298Z","iopub.status.idle":"2022-03-22T09:19:51.424763Z","shell.execute_reply.started":"2022-03-22T09:19:51.417265Z","shell.execute_reply":"2022-03-22T09:19:51.424069Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"compute_correlation(2,104)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T09:20:22.945022Z","iopub.execute_input":"2022-03-22T09:20:22.945414Z","iopub.status.idle":"2022-03-22T09:20:22.966770Z","shell.execute_reply.started":"2022-03-22T09:20:22.945383Z","shell.execute_reply":"2022-03-22T09:20:22.966030Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# all ratings are equal and so the mean is the same as each one of them so x-mean = 0 so the correlation gives 0/0 value","metadata":{"execution":{"iopub.status.busy":"2021-11-25T22:35:26.723542Z","iopub.execute_input":"2021-11-25T22:35:26.723784Z","iopub.status.idle":"2021-11-25T22:35:26.727822Z","shell.execute_reply.started":"2021-11-25T22:35:26.723753Z","shell.execute_reply":"2021-11-25T22:35:26.726818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Think and write your ideas here about why these NaNs exist, and use the cells below to do some coding to validate your thoughts. You can check other pairs of users and see that there are actually many NaNs in our data - 2,526,710 of them in fact. These NaN's ultimately make the correlation coefficient a less than optimal measure of similarity between two users.\n\n\n","metadata":{"id":"6VlemN1fSMQI"}},{"cell_type":"code","source":"# Which movies did both user 2 and user 104 see?\nm = np.intersect1d(movies_to_analyze[2], movies_to_analyze[104])\nm","metadata":{"id":"Fb52nuPYSMQJ","execution":{"iopub.status.busy":"2022-03-22T09:21:22.126604Z","iopub.execute_input":"2022-03-22T09:21:22.126868Z","iopub.status.idle":"2022-03-22T09:21:22.132732Z","shell.execute_reply.started":"2022-03-22T09:21:22.126840Z","shell.execute_reply":"2022-03-22T09:21:22.132182Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# What were the ratings for each user for those movies?\n\nr1 = [reviews.rating[(reviews['user_id'] == 2) & (reviews['movie_id'] == mi)].tolist()[0] for mi in m]\nr2 = [reviews.rating[(reviews['user_id'] == 104) & (reviews['movie_id'] == mi)].tolist()[0] for mi in m]\nprint(r1, r2, sep='\\n')","metadata":{"id":"CqC4KekrSMQK","execution":{"iopub.status.busy":"2022-03-22T09:21:34.610736Z","iopub.execute_input":"2022-03-22T09:21:34.611164Z","iopub.status.idle":"2022-03-22T09:21:34.632946Z","shell.execute_reply.started":"2022-03-22T09:21:34.611130Z","shell.execute_reply":"2022-03-22T09:21:34.632410Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"`6.` Because the correlation coefficient proved to be less than optimal for relating user ratings to one another, we could instead calculate the euclidean distance between the ratings.  I found [this post](https://stackoverflow.com/questions/1401712/how-can-the-euclidean-distance-be-calculated-with-numpy) particularly helpful when I was setting up my function.  This function should be very similar to your previous function.  When you feel confident with your function, test it against our results.","metadata":{"id":"bNY2BsuiSMQM"}},{"cell_type":"code","source":"def compute_euclidean_dist(user1, user2):\n    '''\n    INPUT\n    user1 - int user_id\n    user2 - int user_id\n    OUTPUT\n    the euclidean distance between user1 and user2\n    ''' \n    m1 = movies_to_analyze[user1]\n    m2 = movies_to_analyze[user2]\n    m12 = np.intersect1d(m1,m2)\n    r1 = [reviews.rating[(reviews['user_id'] == user1) & (reviews['movie_id'] == mi)].tolist()[0] for mi in m12]\n    r2 = [reviews.rating[(reviews['user_id'] == user2) & (reviews['movie_id'] == mi)].tolist()[0] for mi in m12]\n   \n    return np.linalg.norm(np.array(r1)-np.array(r2)) #return the euclidean distance","metadata":{"id":"F_rE8-F8SMQN","execution":{"iopub.status.busy":"2022-03-22T09:21:38.442641Z","iopub.execute_input":"2022-03-22T09:21:38.443054Z","iopub.status.idle":"2022-03-22T09:21:38.448971Z","shell.execute_reply.started":"2022-03-22T09:21:38.443018Z","shell.execute_reply":"2022-03-22T09:21:38.448292Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"dists\nfor user1 in movies_to_analyze:\n    for user2 in movies_to_analyze:\n        dists.append(compute_euclidean_dist(user1, user2))\n        \ndf_dists = pd.DataFrame()        \ndf_dists['user1'] = list(movies_to_analyze.keys())\ndf_dists['user2'] = list(movies_to_analyze.keys())\ndf_dists['eucl_dist'] = dists\n\n\n### It will take foreve, so I previously calculated it and I will load it from drive","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown --id 1MpGEx2PWBtmVKydgZSyuFxoz8ds0LGQt","metadata":{"execution":{"iopub.status.busy":"2022-03-22T09:22:17.091665Z","iopub.execute_input":"2022-03-22T09:22:17.091932Z","iopub.status.idle":"2022-03-22T09:22:32.543306Z","shell.execute_reply.started":"2022-03-22T09:22:17.091905Z","shell.execute_reply":"2022-03-22T09:22:32.542319Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Read in solution euclidean distances\"\nimport pickle\ndf_dists = pd.read_pickle(\"dists.p\")","metadata":{"id":"es4TSLj0SMQQ","execution":{"iopub.status.busy":"2022-03-22T09:42:42.988643Z","iopub.execute_input":"2022-03-22T09:42:42.989305Z","iopub.status.idle":"2022-03-22T09:42:45.605210Z","shell.execute_reply.started":"2022-03-22T09:42:42.989255Z","shell.execute_reply":"2022-03-22T09:42:45.604504Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"df_dists.iloc[0]","metadata":{"execution":{"iopub.status.busy":"2022-03-22T09:25:49.301341Z","iopub.execute_input":"2022-03-22T09:25:49.302008Z","iopub.status.idle":"2022-03-22T09:25:49.332929Z","shell.execute_reply.started":"2022-03-22T09:25:49.301967Z","shell.execute_reply":"2022-03-22T09:25:49.332085Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"### Using the Nearest Neighbors to Make Recommendations\n\nIn the previous question, you read in **df_dists**. Therefore, you have a measure of distance between each user and every other user. This dataframe holds every possible pairing of users, as well as the corresponding euclidean distance.\n\nBecause of the **NaN** values that exist within the correlations of the matching ratings for many pairs of users, as we discussed above, we will proceed using **df_dists**. You will want to find the users that are 'nearest' each user.  Then you will want to find the movies the closest neighbors have liked to recommend to each user.\n\nI made use of the following objects:\n\n* df_dists (to obtain the neighbors)\n* user_items (to obtain the movies the neighbors and users have rated)\n* movies (to obtain the names of the movies)\n\n`7.` Complete the functions below, which allow you to find the recommendations for any user.  There are five functions which you will need:\n\n* **find_closest_neighbors** - this returns a list of user_ids from closest neighbor to farthest neighbor using euclidean distance\n\n\n* **movies_liked** - returns an array of movie_ids\n\n\n* **movie_names** - takes the output of movies_liked and returns a list of movie names associated with the movie_ids\n\n\n* **make_recommendations** - takes a user id and goes through closest neighbors to return a list of movie names as recommendations\n\n\n* **all_recommendations** = loops through every user and returns a dictionary of with the key as a user_id and the value as a list of movie recommendations","metadata":{"id":"Uo2Xf97ISMQR"}},{"cell_type":"code","source":"def find_closest_neighbors(user):\n    '''\n    INPUT:\n        user - (int) the user_id of the individual you want to find the closest users\n    OUTPUT:\n        closest_neighbors - an array of the id's of the users sorted from closest to farthest away\n    '''\n    # I treated ties as arbitrary and just kept whichever was easiest to keep using the head method\n    # You might choose to do something less hand wavy - order the neighbors\n    \n    \n    \n    return df_dists[df_dists.user1==user].sort_values(by='eucl_dist').user2.tolist()\n    \n    \n    \ndef movies_liked(user_id, min_rating=7):\n    '''\n    INPUT:\n    user_id - the user_id of an individual as int\n    min_rating - the minimum rating considered while still a movie is still a \"like\" and not a \"dislike\"\n    OUTPUT:\n    movies_liked - an array of movies the user has watched and liked\n    '''\n  \n    return reviews.sort_values(by='rating', ascending=False).movie_id[reviews.rating>=7].tolist()\n\n\ndef movie_names(movie_ids):\n    '''\n    INPUT\n    movie_ids - a list of movie_ids\n    OUTPUT\n    movies - a list of movie names associated with the movie_ids\n    \n    '''\n\n    return movies.movie[movies.movie_id.isin(movie_ids)].tolist()\n    \n    \ndef make_recommendations(user, num_recs=10):\n    '''\n    INPUT:\n        user - (int) a user_id of the individual you want to make recommendations for\n        num_recs - (int) number of movies to return\n    OUTPUT:\n        recommendations - a list of movies - if there are \"num_recs\" recommendations return this many\n                          otherwise return the total number of recommendations available for the \"user\"\n                          which may just be an empty list\n    '''\n    neighbours = find_closest_neighbors(user)\n    my_m = movies_watched(user)\n    recommendations = []\n    u=0\n    \n    while len(recommendations)<num_recs:\n        m = movies_liked(neighbours[u])\n        diff = np.setdiff1d(m, my_m)\n        for i in diff:\n            recommendations.append(i)\n        u+=1       \n    \n    return recommendations\n\ndef all_recommendations(num_recs=10):\n    '''\n    INPUT \n        num_recs (int) the (max) number of recommendations for each user\n    OUTPUT\n        all_recs - a dictionary where each key is a user_id and the value is an array of recommended movie titles\n    '''\n    # Make the recommendations for each user\n    \n    \n    return {u:movie_names(make_recommendations(u, num_recs)) for u in df_dists.user1}\n\nfirst10_recs = all_recommendations(10)\n\nprint(first10_recs)\n\n##  This will take a long time to compute all recommendations for all users","metadata":{"id":"8dsxKiTpSMQS","execution":{"iopub.status.busy":"2022-03-22T09:44:02.410909Z","iopub.execute_input":"2022-03-22T09:44:02.411904Z","iopub.status.idle":"2022-03-22T09:44:02.417108Z","shell.execute_reply.started":"2022-03-22T09:44:02.411861Z","shell.execute_reply":"2022-03-22T09:44:02.416568Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# This loads our solution dictionary so you can compare results\nall_recs_sol = pd.read_pickle(\"all_recs.p\")","metadata":{"id":"h7QBY5NDSMQT","execution":{"iopub.status.busy":"2021-11-25T23:32:32.525018Z","iopub.status.idle":"2021-11-25T23:32:32.525605Z","shell.execute_reply.started":"2021-11-25T23:32:32.525287Z","shell.execute_reply":"2021-11-25T23:32:32.52532Z"},"trusted":true},"execution_count":null,"outputs":[]}]}